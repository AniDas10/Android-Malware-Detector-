"""
Driver file for training and all major steps
- Feature Engineering
- Feature Selection
- Cross validation
- Using metrics
- Calling different models
- Saving trained models

"""

import argparse
import os
import config
import joblib
import pandas as pd
from sklearn import metrics
from sklearn import tree
import dispatcher
from feature_engg import feature_engineering
from feature_selection import feature_selection
from preprocess import filter_columns

def run(fold, model):
    df = pd.read_csv(config.TRAINING_FILE)

    redundant_columns = ['Unnamed: 0.1', 'Description', 'Category', 
                        'App', 'Related apps', 'Package',
                         'Safe permissions count']
    safeCols = [col for col in df.columns if '(S)' in col]

    # filtering out redundant columns
    df = filter_columns(df, redundant_columns+safeCols)
    
    # training data is where kFold is not equal to the fold number
    df_train = df[df.kfold != fold].reset_index(drop=True)
    
    # feature engineering and selection 
    # customise the working in their respective parent .py file
    df_train = feature_engineering(df_train)
    selected_columns = feature_selection(df_train, df_train.Class.values)
    
    # validation data is where kfold is equal to the fold number
    df_valid = df[df.kfold == fold].reset_index(drop=True)
    df_valid = feature_engineering(df_valid)
    
    # Splitting our data into train and valid dfs.
    x_train = df_train[selected_columns]
    y_train = df_train.Class.values

    x_valid = df_valid[selected_columns]
    y_valid = df_valid.Class.values


    # lets use a simple tree classifier as our baseline model first
    # we can feature engineer ahead and this would be the baseline we need to improve on
    clf = dispatcher.models[model]

    # fitting out model
    clf.fit(x_train, y_train)

    # creating predictions for validation set
    preds = clf.predict(x_valid)

    # metrics for evaluation
    accuracy = metrics.accuracy_score(y_valid, preds)
    recall = metrics.recall_score(y_valid, preds)
    precision = metrics.precision_score(y_valid, preds)
    f1 = metrics.f1_score(y_valid, preds)
    print(f'Fold={fold}, Accuracy = {accuracy}')
    print(f'Fold={fold}, Recall = {recall}')
    print(f'Fold={fold}, Precision = {precision}')
    print(f'Fold={fold}, F1 = {f1}')

    # save the model
    joblib.dump(clf, os.path.join(config.MODEL_OUTPUT, f'baseline_dt_{fold}.bin'))


if __name__=='__main__':
    """
    # uncomment this section to simply run train.py and get the models

    run(fold=0, rf)
    run(fold=1, rf)
    run(fold=2, rf)
    run(fold=3, rf)
    run(fold=4, rf)
    """

    # to run it fold wise and assign a specific model to each fold
    # in cmd: python train.py --fold 0 --model decision_tree_gini
    # in cmd: python train.py --fold 1 --model decision_tree_entropy
    # in cmd: python train.py --fold 2 --model rf
    # the available list of model names are prseent in our dispatcher.py file
    # from here we will dispatch all models so it is flexible to change in the future

    parser = argparse.ArgumentParser()

    # now we add the different arguments we need and their type
    parser.add_argument("--fold", type=int)
    parser.add_argument("--model", type=str)

    # read arguments from cmd
    args = parser.parse_args()

    # and now we run it based on args received
    run(fold=args.fold, model=args.model)
